# ğŸ’³ End-to-End Credit Card Fraud Detection with MLOps

This project demonstrates a complete MLOps lifecycle for a credit card fraud detection system, implementing Google MLOps whitepaper best practices. It covers the entire machine learning pipeline from data ingestion to production deployment.

## ğŸ›ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Source   â”‚â”€â”€â”€â–¶â”‚  Data Pipeline  â”‚â”€â”€â”€â–¶â”‚  Model Training â”‚
â”‚   (Credit Card  â”‚    â”‚  (Preprocessing â”‚    â”‚  (MLflow)       â”‚
â”‚    Transactions)â”‚    â”‚   + Validation) â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Monitoring    â”‚    â”‚   CI/CD         â”‚    â”‚   Model Serving  â”‚
â”‚   (Drift + Perf)â”‚    â”‚   (GitHub       â”‚    â”‚   (Flask REST    â”‚
â”‚                 â”‚    â”‚    Actions)     â”‚    â”‚    API)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tech Stack

- **Data Versioning**: DVC (Git-based data versioning)
- **Experiment Tracking**: MLflow (model versioning, metrics, artifacts)
- **Pipeline Orchestration**: Prefect (workflow automation)
- **Model Serving**: Flask REST API (real-time predictions)
- **Monitoring**: Custom drift detection + performance monitoring
- **CI/CD**: GitHub Actions (automated testing & deployment)
- **Infrastructure**: Docker + Kubernetes (containerization & orchestration)
- **Development**: Python 3.10, scikit-learn, pandas

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- Docker (optional, for containerized deployment)

### Setup
```bash
# Clone repository
git clone <repository-url>
cd fraud-detection-mlops

# Install dependencies
pip install -r requirements.txt

# Verify data exists
ls data/raw/ data/processed/
```

### ğŸ¯ Serve Model (Simplest Approach)
```bash
# One-command solution: retrain + serve
python retrain_and_serve.py

# Web interface available at http://localhost:3000
```

### ğŸŒ Web Interface & Authentication
The system includes a professional web interface with authentication:

#### **ğŸ” Authentication**
- **Session-based login system** with multiple demo accounts
- **Secure access control** for all fraud detection features
- **Role-based permissions** (admin/user access levels)

#### **ğŸ’» Web Interface Features**
1. **Simple Form**: Only requires Transaction Time and Amount
2. **Real-time Validation**: Green/red feedback as you type
3. **Smart Backend**: Automatically uses representative sample data
4. **Visual Results**: Instant analysis with confidence scores and bars
5. **Professional UI**: Modern, responsive design for all devices
6. **Loading States**: Real-time feedback during processing

#### **ğŸ¯ Demo Accounts**
```
Username: demo     / Password: demo     (Regular User)
Username: admin    / Password: admin    (Administrator)
Username: user     / Password: password (Regular User)
```

### ğŸ§ª Test the API
```bash
# Health check
curl http://localhost:3000/health

# JSON API prediction (full features)
curl -X POST http://localhost:3000/predict \
  -H "Content-Type: application/json" \
  -d '{"Time": 125.5, "Amount": 49.99, "...": "all features"}'

# Web form prediction (simplified)
curl -X POST http://localhost:3000/predict/form \
  -d "Time=125.50&Amount=49.99"
```

## ğŸ”„ MLOps Pipeline Steps

This project implements the complete MLOps lifecycle following Google MLOps whitepaper principles:

### 1. ğŸ“Š **Data Management**
- **Data Ingestion**: Raw credit card transaction data (284K+ samples)
- **Data Versioning**: DVC tracks data changes and enables reproducibility
- **Data Validation**: Automated quality checks and anomaly detection
- **Preprocessing**: Feature scaling, normalization, and imbalance handling

```bash
# Check data status
dvc status

# Pull latest data (if using remote storage)
dvc pull
```

### 2. ğŸ—ï¸ **Model Development**
- **Experiment Tracking**: MLflow logs all experiments, parameters, and metrics
- **Hyperparameter Tuning**: Automated optimization using Optuna
- **Model Training**: Multiple algorithms with cross-validation
- **Model Evaluation**: Comprehensive metrics (AUC, precision, recall, F1)

```bash
# Run training pipeline
python pipelines/training_pipeline.py

# View experiments in MLflow UI
mlflow ui
```

### 3. âœ… **Model Validation & Testing**
- **Cross-Validation**: Robust performance estimation
- **Business Metrics**: Fraud detection specific KPIs
- **Model Registry**: Version control and staging (Development â†’ Staging â†’ Production)
- **Automated Testing**: Unit tests and integration tests

```bash
# Run tests
make test

# Check code quality
make lint
```

### 4. ğŸš€ **Model Deployment**
- **Containerization**: Docker images for consistent deployment
- **Orchestration**: Kubernetes manifests for production scaling
- **CI/CD**: GitHub Actions automate testing and deployment
- **Blue-Green Deployment**: Zero-downtime releases with rollback capability

```bash
# Build and deploy
make build
make deploy

# Or use Docker Compose for local testing
docker-compose -f infra/docker/docker-compose.yml up -d
```

### 5. ğŸ‘ï¸ **Monitoring & Observability**
- **Data Drift Detection**: Monitors feature distribution changes
- **Model Performance**: Tracks accuracy decay over time
- **Automated Alerts**: Notifications for critical issues
- **Retraining Triggers**: Automatic model updates when needed

```bash
# Run monitoring pipeline
python pipelines/monitoring_pipeline.py

# View monitoring logs
ls monitoring_logs/
```

### 6. ğŸ”’ **Production Serving**
- **REST API**: Flask-based HTTP endpoints for real-time predictions
- **Health Checks**: Automated service monitoring
- **Load Balancing**: Multiple replicas for high availability
- **Security**: Non-root containers, minimal attack surface

```bash
# Start production server
python retrain_and_serve.py

# API Endpoints:
# GET  /health     - Service health check
# GET  /           - API information
# POST /predict    - Real-time fraud prediction
```

## ğŸ“ Project Structure

```
fraud-detection-mlops/
â”œâ”€â”€ ğŸ“Š data/                    # Data management
â”‚   â”œâ”€â”€ raw/                    # Raw transaction data
â”‚   â””â”€â”€ processed/              # Preprocessed features
â”œâ”€â”€ ğŸ¤– models/                  # Trained models & artifacts
â”œâ”€â”€ ğŸ”§ src/                     # Source code
â”‚   â”œâ”€â”€ data/                   # Data processing scripts
â”‚   â””â”€â”€ models/                 # ML model code
â”œâ”€â”€ ğŸ”„ pipelines/               # MLOps pipelines
â”‚   â”œâ”€â”€ training_pipeline.py    # Automated training
â”‚   â”œâ”€â”€ deployment_pipeline.py  # Deployment automation
â”‚   â””â”€â”€ monitoring_pipeline.py  # Performance monitoring
â”œâ”€â”€ ğŸ³ infra/                   # Infrastructure as code
â”‚   â”œâ”€â”€ docker/                 # Container definitions
â”‚   â””â”€â”€ k8s/                    # Kubernetes manifests
â”œâ”€â”€ ğŸ§ª tests/                   # Test suites
â”œâ”€â”€ ğŸ“ˆ mlruns/                  # MLflow experiment logs
â”œâ”€â”€ ğŸ”„ mlartifacts/             # MLflow model artifacts
â””â”€â”€ ğŸ“‹ requirements.txt         # Python dependencies
```

## ğŸ¯ Key Features

- **ğŸ”„ Continuous Training**: Automated model retraining on new data
- **ğŸ“Š Experiment Tracking**: Full lineage from data to predictions
- **ğŸ” Data Validation**: Automated drift detection and quality checks
- **ğŸš€ One-Click Deployment**: Docker + Kubernetes for production
- **ğŸ“ˆ Performance Monitoring**: Real-time model health tracking
- **ğŸ”’ Production Ready**: Security hardened, scalable architecture

## ğŸ› ï¸ Available Commands

```bash
# Development
make install          # Install dependencies
make test            # Run test suite
make lint            # Code quality checks
make serve           # Start local model server

# Deployment
make build           # Build Docker image
make deploy          # Deploy to Kubernetes
docker-compose up    # Start local stack

# Pipelines
make train           # Run training pipeline
make monitor         # Run monitoring pipeline

# Cleanup
make clean           # Remove artifacts
```

## ğŸ“Š Model Performance

Current model achieves:
- **AUC-ROC**: 0.967 (excellent fraud detection)
- **Precision**: High precision on fraud predictions
- **Recall**: Strong recall for catching fraudulent transactions
- **F1-Score**: Balanced performance metric

## ğŸ”® Future Enhancements

- [ ] **A/B Testing**: Compare model versions in production
- [ ] **Feature Store**: Centralized feature management
- [ ] **Model Explainability**: SHAP/LIME integration
- [ ] **Multi-Model Serving**: Ensemble predictions
- [ ] **Advanced Monitoring**: Prometheus + Grafana dashboards

---

**Built with â¤ï¸ following MLOps best practices**
```
